{"cells":[{"cell_type":"markdown","metadata":{"id":"Fc9hy1EOz5Gn"},"source":["# 16장 - 순환 신경망으로 순차 데이터 모델링 (part 1)"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"GzhUV8f7z5Go","executionInfo":{"status":"ok","timestamp":1669286507861,"user_tz":-540,"elapsed":53,"user":{"displayName":"한현구","userId":"08987249905342132055"}}},"outputs":[],"source":["from IPython.display import Image"]},{"cell_type":"markdown","metadata":{"id":"EhhU7t-4z5Gp"},"source":["# 순차 데이터 소개"]},{"cell_type":"markdown","metadata":{"id":"H02oaZkMz5Gp"},"source":["시퀀스 데이터 또는 **시퀀스**(sequence)로 불리는 순차 데이터의 특징에 관해 알아보면서 RNN을 알아보자.  \n","시퀀스에는 다른 종류의 데이터와는 구별되는 독특한 성질이 있다. 시퀀스 데이터를 표현하는 방법과 시퀀스 데이터를 위한 여러 가지 모델을 살펴보자."]},{"cell_type":"markdown","metadata":{"id":"rvQAqCH7z5Gp"},"source":["## 순차 데이터 모델링: 순서를 고려한다"]},{"cell_type":"markdown","metadata":{"id":"llTEW9fIz5Gq"},"source":["다른 데이터 타입과 다르게 시퀀스는 특별하다. 시퀀스 원소들은 특성 순서가 있으므로 상호 독립적이지 않기 때문이다. 일반적으로 지도 학습을 위한 머신 러닝 알고리즘은 입력 데이터가 **독립 동일 분포**(Independent and Identically Ditributed, IID)라고 가정한다. 즉, 훈련 샘플이 상호 독립(mutually indenpendence)적이고 같은 분포에 속한다는 의미이다.  \n","상호 독립 가정에 기반한다는 점에서 모델에 전달되는 훈련 샘플의 순서는 관계가 없다. 붓꽃 데이터셋에서 각 꽃은 개별적으로 측정되었고 한 꽃의 측정값이 다른 꽃의 측정값에 영향을 미치지 않는다.  \n","\n","하지만 시퀀스를 다룰 때는 이런 가정이 유효하지 않다. 시퀀스의 정의가 순서를 고려하기 떄문이다. 특정 주식의 가격을 예측하는 것이 이런 경우에 해당한다. 예를 들어 n개의 훈련 샘플을 가지고 있다면 각 훈련 샘플을 특정한 날의 이 주식 가격을 나타낸다. 다음 3일 동안의 주식 가격을 예측하는 작업이라면 훈련 샘플을 랜덤 순서로 사용하는 것이 아니라 날짜 순서대로 정렬된 이전 주식 가격을 고려하여 트렌드를 감지하는 것이 합리적이다. "]},{"cell_type":"markdown","metadata":{"id":"ckVTskyrz5Gq"},"source":["### Note\n","#### 순차 데이터 vs 시계열 데이터\n","시계열(time series) 데이터는 순차 데이터의 특별한 한 종류이다. 각 샘플이 시간 차원에 연관되어 있다. 시계열 데이터에서는 연속적인 타임스탬프를 따라 샘플을 얻는다. 따라서 시간 차원이 데이터 포인트 사이의 순서를 결정한다. 예를 들어 주식 가격과 녹화된 음성이나 대화가 시계열 데이터이다.  \n","\n","모든 순차 데이터가 시간 차원을 가지는 것은 아니다. 예를 들어 텍스트 데이터나 DNA 시퀀스는 샘플이 순서를 가지지만 시계열 데이터로 볼 수 없다. 이 장에서 보겠지만 자연어 처리(Natural Language Preprocessing, NLP)와 테스트 모델링의 샘플은 시계열 데이터가 아니다. 하지만 RNN은 시계열 데이터에 사용할 수 있다."]},{"cell_type":"markdown","metadata":{"id":"vxzKf05Cz5Gq"},"source":["## 시퀀스 표현"]},{"cell_type":"markdown","metadata":{"id":"1re_FteZz5Gq"},"source":["순차 데이터에서 데이터 포인트 사이의 순서가 중요하다는 것을 이해했다. 따라서 머신 러닝 모델에서 이런 순서 정보를 사용할 수 있는 방법을 찾아야 한다.  \n","이 장에서 시퀀스를 $<x^{(1)}, x^{(2)}, \\cdots, x^{(T)}>$로 표현한다. 위 첨자는 샘플 순서를 나타낸다. $T$는 시퀀스 길이이다. 시퀀스의 좋은 예는 시계열 데이터이다. 여기서 각 샘플 포인트 $x^{(t)}$는 특정 시간 t에 속한다. "]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":302},"id":"F4_q0COKz5Gq","executionInfo":{"status":"ok","timestamp":1669286507864,"user_tz":-540,"elapsed":53,"user":{"displayName":"한현구","userId":"08987249905342132055"}},"outputId":"2291d39b-23f4-4cf0-c876-6da98da99b86"},"outputs":[{"output_type":"execute_result","data":{"text/html":["<img src=\"https://git.io/JLdVm\" width=\"700\"/>"],"text/plain":["<IPython.core.display.Image object>"]},"metadata":{},"execution_count":2}],"source":["Image(url='https://git.io/JLdVm', width=700)"]},{"cell_type":"markdown","metadata":{"id":"c2jcGpUOz5Gr"},"source":["다층 퍼셉트론(MLP)이나 이미지 데이터를 위한 CNN과 같이 지금까지 다루었던 일반 신경망 모델은 훈련 샘플이 서로 독립적이어서 순서 정보와 연관이 없다고 가정한다.  \n","이런 모델은 이전에 본 훈련 샘플을 기억하는 메모리가 없다고 말한다. 예를 들어 샘플이 정방향 계산과 역전파 단계를 통과하면 가중치는 훈련 샘플의 처리 순서에 상관없이 독립적으로 업데이트된다.  \n","\n","이와 대조적으로 RNN은 시퀀스 모델링을 위해 고안되었으며 과거 정보를 기억하고 이에 맞추어 새로운 샘플을 처리할 수 있기 때문에 시퀀스 데이터를 다룰 때 장점을 가진다."]},{"cell_type":"markdown","metadata":{"id":"8-0g-4rEz5Gr"},"source":["## 시퀀스 모델링의 종류"]},{"cell_type":"markdown","metadata":{"id":"CyOjPg7rz5Gr"},"source":["시퀀스 모델링에서는 언어 번역, 이미지 캡셔닝(captioning), 텍스트 생성과 같은 매력적인 애플리케이션이 많다. 하지만 적절한 구조와 방법을 찾으려면 여러 종류의 시퀀스 모델링 작업 사이의 차이점을 이해하고 구별할 수 있어야 한다.  "]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":446},"id":"BapeiFR3z5Gr","executionInfo":{"status":"ok","timestamp":1669286507866,"user_tz":-540,"elapsed":49,"user":{"displayName":"한현구","userId":"08987249905342132055"}},"outputId":"8e3dfbd5-4c21-4bd0-8fe2-29b74de91f85"},"outputs":[{"output_type":"execute_result","data":{"text/html":["<img src=\"https://git.io/JLdVO\" width=\"700\"/>"],"text/plain":["<IPython.core.display.Image object>"]},"metadata":{},"execution_count":3}],"source":["Image(url='https://git.io/JLdVO', width=700)"]},{"cell_type":"markdown","metadata":{"id":"v7p7iVN_z5Gs"},"source":["위의 그림에 나와 있는 입력과 출력 데이터 사이에 나타나는 여러 관계에 대해 자세히 알아보자.  \n","입력과 출력 데이터가 시퀀스로 표현되지 않으면 일반 데이터이므로 간단히 다층 퍼헵트론을 사용할 수 있다. 하지만 입력이나 출력 중 하나가 시퀀스라면 이런 모델링 작업은 다음 중 하나에 속할 것이다.  \n","\n","- **다대일**(many-to-one): 입력 데이터가 시퀀스이지만 출력은 시퀀스가 아니고 고정 크기의 벡터나 스칼라이다. 예를 들어 감성 분석에서 입력은 텍스트(예를 들어 영화 리뷰)이고 출력은 클래스 레이블(예를 들어 리뷰어가 영화를 좋아하는지 나타내는 레이블)이다.  \n","\n","- **일대다**(one-to-many): 입력 데이터가 시퀀스가 아니라 일반적인 형태이고 출력은 시퀀스이다. 이런 종류의 예로는 이미지 캡셔닝이 있다. 입력이 이미지이고 출력은 이미지 내용을 요약한 영어 문장이다.  \n","\n","- **다대다**(many-to-many): 입력과 출력 배열이 모두 시퀀스이다. 이런 종류는 입력과 출력이 동기적인지에 따라 더 나눌 수 있다. 동기적인 다대다 모델링 작업의 예는 각 프레임을 레이블링하는 비디오 분류이다. 지연이 있는 다대다 모델의 예는 한 언어에서 다른 언어로 번역하는 작업이다. 예를 들어 독일어로 번역하기 전에 전체 영어 문장을 읽어 처리한다. "]},{"cell_type":"markdown","metadata":{"id":"AklSc49qz5Gs"},"source":["# 시퀀스 모델링을 위한 RNN"]},{"cell_type":"markdown","metadata":{"id":"nDKTbQKLz5Gs"},"source":["## RNN 반복 구조 이해"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":330},"id":"EjkuoZ_xz5Gs","executionInfo":{"status":"ok","timestamp":1669286507867,"user_tz":-540,"elapsed":48,"user":{"displayName":"한현구","userId":"08987249905342132055"}},"outputId":"0458180a-2c10-44f6-f6e2-a5102611e79d"},"outputs":[{"output_type":"execute_result","data":{"text/html":["<img src=\"https://git.io/JLdV3\" width=\"700\"/>"],"text/plain":["<IPython.core.display.Image object>"]},"metadata":{},"execution_count":4}],"source":["Image(url='https://git.io/JLdV3', width=700)"]},{"cell_type":"markdown","metadata":{"id":"YY1q0662z5Gs"},"source":["위의 그림에서 일반적인 피드포워드 신경망과 RNN을 비교하기 위해 나란히 놓았다.  \n","두 네트워크 모두 하나의 은닉층만 있다. 유닛을 표시하지 않았다.  \n","\n","기본 피드포워드 네트워크에서 정보는 입력에서 은닉층으로 흐른 후 은닉층에서 출력층으로 전달된다. 반면 순한 네트워크에서는 은닉층이 현재 타임 스텝(time step)의 입력층과 이전 타임 스텝의 은닉층으로부터 정보를 받는다.  \n","\n","인접한 타임 스텝의 정보가 은닉층에 흐르기 때문에 네트워크가 이전 이벤트를 기억할 수 있다. 이 정보 흐름을 보통 루프로 표시한다. 그래프 표기법에서는 순환 에지(recurrent edge)라고도 하기 때문에 RNN구조 이름이 여기서 유래되었다.  \n","\n","다층 퍼셉트론과 비슷하게 RNN은 여러 개의 은닉층으로 구성할 수 있다. 하나의 은닉층을 가진 RNN을 관례적으로 단일층 RNN이라고 말한다. 아달린이나 로지스틱 회귀와 같이 은닉층이 없는 단일층 신경망과 혼동하면 안된다."]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":632},"id":"dS6fySVPz5Gs","executionInfo":{"status":"ok","timestamp":1669286507868,"user_tz":-540,"elapsed":46,"user":{"displayName":"한현구","userId":"08987249905342132055"}},"outputId":"87dd8e8c-a446-478c-cd89-b1d720cc4192"},"outputs":[{"output_type":"execute_result","data":{"text/html":["<img src=\"https://git.io/JLdVs\" width=\"700\"/>"],"text/plain":["<IPython.core.display.Image object>"]},"metadata":{},"execution_count":5}],"source":["Image(url='https://git.io/JLdVs', width=700)"]},{"cell_type":"markdown","metadata":{"id":"lxN7NMpLz5Gs"},"source":["위의 그림은 하나의 은닉층을 가진 RNN과 두 개의 은닉층을 가진 RNN을 보여준다.  \n","\n","일반 신경망의 은닉 유닛은 입력층에 연결된 최종 입력 하나만 받는다. 반면 RNN은 은닉 유닛은 두 개의 다른 입력을 받는다. *입력층으로부터 받은 입력*과 같은 은닉층에서 *t-1 타임 스텝의 활성화 출력*을 받는다.   \n","\n","맨 처음 t=0에서는 은닉 유닛이 0또는 작은 난수로 초기화된다. t>0인 타임 스텝에서는 은닉 유닛이 현재 타임 스텝의 데이터 포인트 $x^{(t)}$와 이전 타임 스텝 t-1의 은닉 유닛 값 $h^{(t-1)}$을 입력으로 받는다.  "]},{"cell_type":"markdown","metadata":{"id":"F6jdkZbNz5Gt"},"source":["## RNN의 활성화 출력 계산"]},{"cell_type":"markdown","metadata":{"id":"DLP5oAQvz5Gt"},"source":["위의 그림에서 유향 에지(directed edge)(층 사이 연결과 순환 연결)는 가중치 행렬과 연관된다. 이 가중치는 특정 시간 t에 종속적이지 않고 전체 시간 축에 공유된다. 단일층 RNN의 각 가중치는 다음과 같다.  \n","\n","- $W_{xh}$: 입력 $x^{(t)}$와 은닉층 $h$ 사이의 가중치 행렬  \n","- $W_{hh}$: 순환 에지에 연관된 가중치 행렬  \n","- $W_{ho}$: 은닉층과 출력층 사이의 가중치 행렬"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":314},"id":"3XZ4-6e7z5Gt","executionInfo":{"status":"ok","timestamp":1669286507869,"user_tz":-540,"elapsed":45,"user":{"displayName":"한현구","userId":"08987249905342132055"}},"outputId":"4edc3131-7375-46af-8773-fdfaaf733776"},"outputs":[{"output_type":"execute_result","data":{"text/html":["<img src=\"https://git.io/JLdVC\" width=\"700\"/>"],"text/plain":["<IPython.core.display.Image object>"]},"metadata":{},"execution_count":6}],"source":["Image(url='https://git.io/JLdVC', width=700)"]},{"cell_type":"markdown","metadata":{"id":"YXnmn087z5Gt"},"source":["구현에 따라 가중치 행렬 $W_{xh}$와 $W_{hh}$를 합쳐 연결된 행렬 $W_{h}=[W_{xh};W_{hh}]$를 사용한다. \n","\n","활성화 출력의 계산은 기본적인 다층 퍼셉트론이나 다른 피드포워드 신경망과 매우 비슷하다. 은닉층의 최종 입력 $z_{h}$(활성화 함수를 통과하기 전의 값)는 선형 조합으로 계산된다. 즉, 가중치 행렬과 대응되는 벡터를 곱해서 더한 후 절편 유닛을 더한다."]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":392},"id":"soUOV1Ohz5Gt","executionInfo":{"status":"ok","timestamp":1669286507870,"user_tz":-540,"elapsed":44,"user":{"displayName":"한현구","userId":"08987249905342132055"}},"outputId":"6b07d96a-8775-4342-d1be-5ee522990f6a"},"outputs":[{"output_type":"execute_result","data":{"text/html":["<img src=\"https://git.io/JLdVW\" width=\"700\"/>"],"text/plain":["<IPython.core.display.Image object>"]},"metadata":{},"execution_count":7}],"source":["Image(url='https://git.io/JLdVW', width=700)"]},{"cell_type":"markdown","metadata":{"id":"_B1CeuFzz5Gu"},"source":["위의 그림은 활성화 출력을 계산하는 과정이다."]},{"cell_type":"markdown","metadata":{"id":"XKVnZiAsz5Gu"},"source":["## 은닉 순환과 출력 순환"]},{"cell_type":"markdown","metadata":{"id":"RemimMogz5Gu"},"source":["지금까지 은닉층에 순환 성질이 있는 순환 신경망을 보았다. 하지만 출력층에서 오는 순환 연결을 가진 모델도 있다. 이런 경우에 이전 타임 스텝의 출력층에서 오는 활성화 $o^{t-1}$을 추가하는 방법은 다음 둘 중 하나이다.  \n","- 현재 타임 스텝에서 은닉층 $h^{t}$에 추가한다.  \n","- 현재 타임 스텝에서 출력층 $o^{t}$에 추가한다.  "]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":622},"id":"VEmYPZSXz5Gv","executionInfo":{"status":"ok","timestamp":1669286507872,"user_tz":-540,"elapsed":44,"user":{"displayName":"한현구","userId":"08987249905342132055"}},"outputId":"7ba5e143-ded2-49fa-869d-68399442b8e4"},"outputs":[{"output_type":"execute_result","data":{"text/html":["<img src=\"https://git.io/JLdV8\" width=\"700\"/>"],"text/plain":["<IPython.core.display.Image object>"]},"metadata":{},"execution_count":8}],"source":["Image(url='https://git.io/JLdV8', width=700)"]},{"cell_type":"markdown","metadata":{"id":"7bZ-pcLsz5Gv"},"source":["실제로 어떻게 동작하는지 보기 위해 이 순환 타입 중 하나의 정방향 계산을 수동으로 수행해 보자. 텐서플로 케라스 API의 `SimpleRNN` 클래스로 출력-출력 순환과 비슷한 순환 층을 정의할 수 있다.  "]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GWF0BkaNz5Gv","executionInfo":{"status":"ok","timestamp":1669286515345,"user_tz":-540,"elapsed":7515,"user":{"displayName":"한현구","userId":"08987249905342132055"}},"outputId":"f30b0319-b098-47ad-ba7f-256029a39c80"},"outputs":[{"output_type":"stream","name":"stdout","text":["W_xh 크기: (5, 2)\n","W_oo 크기: (2, 2)\n","b_h 크기: (2,)\n"]}],"source":["import tensorflow as tf\n","tf.random.set_seed(1)\n","\n","rnn_layer = tf.keras.layers.SimpleRNN(\n","    units=2, use_bias=True, \n","    return_sequences=True)\n","rnn_layer.build(input_shape=(None, None, 5))\n","\n","w_xh, w_oo, b_h = rnn_layer.weights\n","\n","print('W_xh 크기:', w_xh.shape)\n","print('W_oo 크기:', w_oo.shape)\n","print('b_h 크기:', b_h.shape)"]},{"cell_type":"markdown","metadata":{"id":"hgQ-qQF-z5Gv"},"source":["이 층의 입력 크기는 (None, None, 5)이다.  \n","첫 번째 차원은 배치 차원(가변적인 배치 크기를 위해 None으로 지정)이고 두 번째 차원은 시퀀스에 해당한다.(가변적인 시퀀스 길이를 위해 None으로 지정) 마지막 차원은 특성에 해당한다. `return_sequence=True`로 지정했으므로 길이가 3인 시퀀스를 입력하면 출력 시퀀스 $<o^{(0)}, o^{(1)}, o^{(2)}>$가 나온다. 그렇지 않으면 최종 출력 $o^{(2)}$만 반환된다."]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YJf7Dw9cz5Gw","executionInfo":{"status":"ok","timestamp":1669286518688,"user_tz":-540,"elapsed":3348,"user":{"displayName":"한현구","userId":"08987249905342132055"}},"outputId":"af0b149d-4f69-4f3e-c89c-13d55f11b9c0"},"outputs":[{"output_type":"stream","name":"stdout","text":["타임 스텝 0 =>\n","   입력           : [[1. 1. 1. 1. 1.]]\n","   은닉           : [[0.41464037 0.96012145]]\n","   출력 (수동)     : [[0.39240566 0.74433106]]\n","   SimpleRNN 출력 : [0.39240566 0.74433106]\n","\n","타임 스텝 1 =>\n","   입력           : [[2. 2. 2. 2. 2.]]\n","   은닉           : [[0.82928073 1.9202429 ]]\n","   출력 (수동)     : [[0.80116504 0.99129474]]\n","   SimpleRNN 출력 : [0.80116504 0.99129474]\n","\n","타임 스텝 2 =>\n","   입력           : [[3. 3. 3. 3. 3.]]\n","   은닉           : [[1.243921  2.8803642]]\n","   출력 (수동)     : [[0.95468265 0.99930704]]\n","   SimpleRNN 출력 : [0.95468265 0.99930704]\n","\n"]}],"source":["x_seq = tf.convert_to_tensor(\n","    [[1.0]*5, [2.0]*5, [3.0]*5],\n","    dtype=tf.float32)\n","\n","\n","## SimepleRNN의 출력:\n","output = rnn_layer(tf.reshape(x_seq, shape=(1, 3, 5)))\n","\n","## 수동으로 출력 계산하기:\n","out_man = []\n","for t in range(len(x_seq)):\n","    xt = tf.reshape(x_seq[t], (1, 5))\n","    print('타임 스텝 {} =>'.format(t))\n","    print('   입력           :', xt.numpy())\n","    \n","    ht = tf.matmul(xt, w_xh) + b_h    \n","    print('   은닉           :', ht.numpy())\n","    \n","    if t>0:\n","        prev_o = out_man[t-1]\n","    else:\n","        prev_o = tf.zeros(shape=(ht.shape))\n","        \n","    ot = ht + tf.matmul(prev_o, w_oo)\n","    ot = tf.math.tanh(ot)\n","    out_man.append(ot)\n","    print('   출력 (수동)     :', ot.numpy())\n","    print('   SimpleRNN 출력 :'.format(t), output[0][t].numpy())\n","    print()"]},{"cell_type":"markdown","metadata":{"id":"ZasZ-d3Xz5Gw"},"source":["수동으로 정방향 계산을 할 때 하이퍼볼릭 탄젠트(tanh) 활성화 함수를 사용했다. `SimpleRNN`에서 이 함수를 사용하기 때문이다.  \n","출력 결과에서 볼 수 있듯이 수동으로 계산한 것과 `SimpleRNN` 층의 각 타임 스텝 출력이 정확히 동일하다."]},{"cell_type":"markdown","metadata":{"id":"Q7sjDTNMz5Gw"},"source":["## 긴 시퀀스 학습의 어려움"]},{"cell_type":"markdown","metadata":{"id":"6CCqqTLaz5Gx"},"source":["BPTT(BackPropagation Through Time)는 새로운 문제를 야기시킨다. 손실 함수의 그레이디언트를 계산할 때 곱셈 항${\\partial h^{(t)} \\over \\partial h^{(k)}}$ 때문에 소위 **그레이디언트 폭주**(exploding gradient) 또는 **그레이디언트 소실**(vanishing gradient) 문제가 발생한다. "]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":371},"id":"5__Su4umz5Gx","executionInfo":{"status":"ok","timestamp":1669286518690,"user_tz":-540,"elapsed":23,"user":{"displayName":"한현구","userId":"08987249905342132055"}},"outputId":"d307ea4f-ef40-4104-dd00-d2fb639c135e"},"outputs":[{"output_type":"execute_result","data":{"text/html":["<img src=\"https://git.io/JLdV4\" width=\"700\"/>"],"text/plain":["<IPython.core.display.Image object>"]},"metadata":{},"execution_count":11}],"source":["Image(url='https://git.io/JLdV4', width=700)"]},{"cell_type":"markdown","metadata":{"id":"7QnATlXbz5Gx"},"source":["기본적으로 ${\\partial h^{(t)} \\over \\partial h^{(k)}}$는 t-k개의 곱셈으로 이루어진다. 즉, 가중치 w가 t-k번 곱해져 $w^{t-k}$가 된다.  \n","결국 $|w|<1$이면 t-k가 클 때 이 항이 매우 작아진다. 반면 순환 에지의 가중치 값이 $|w|>1$이면 t-k가 클 때 $w^{t-k}$가 매우 커진다. t-k값이 크다는 것은 긴 시간 의존성을 가진다는 의미이다.  \n","그레이디언트 소실이나 폭주를 피하는 단순한 방법은 $|w|=1$이 되도록 만드는 것이다.  \n","\n","실전에서 이 문제에 대한 세 가지 해결책은 다음과 같다.  \n","- 그레이디언트 클리핑\n","- TBPTT(Truncated BackPropagation Through Time)\n","- LSTM(Long Short-Term Memory)  "]},{"cell_type":"markdown","metadata":{"id":"VZ4zPWv3z5Gx"},"source":["## LSTM 셀"]},{"cell_type":"markdown","metadata":{"id":"jcYLm9Hjz5Gx"},"source":["LSTM은 그레이디언트 소실 문제를 극복하기 위해 처음 소개되었다. LSTM의 기본 구성 요소는 일반 RNN의 은닉층을 표현 또는 대체하는 **메모리 셀**(memory cell)이다.  \n","\n","그레이디언트 소실과 폭주 문제를 극복하기 위해 각 메모리 셀에 적절한 가중치 w=1을 유지하는 순환 에지가 있다. 이 순환 에지의 출력을 **셀 상태**(cell state)라고 한다. "]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":400},"id":"Q3qSrGsrz5Gy","executionInfo":{"status":"ok","timestamp":1669286518691,"user_tz":-540,"elapsed":20,"user":{"displayName":"한현구","userId":"08987249905342132055"}},"outputId":"5452aa83-8395-4f45-a584-f3cf82f36f57"},"outputs":[{"output_type":"execute_result","data":{"text/html":["<img src=\"https://git.io/JLdVR\" width=\"700\"/>"],"text/plain":["<IPython.core.display.Image object>"]},"metadata":{},"execution_count":12}],"source":["Image(url='https://git.io/JLdVR', width=700)"]},{"cell_type":"markdown","metadata":{"id":"u0HiQ2lwz5Gy"},"source":["이전 타임 스텝의 셀 상태 $C^{(t-1)}$은 어떤 가중치와도 직접 곱해지지 않고 변경되어 현재 타임 스텝의 셀 상태 $C^{(t)}$을 얻는다.  \n","\n","메모리 셀의 정보 흐름은 다음에 기술된 몇 개의 연산 유닛(또는 게이트)으로 제어된다.  \n","그림에서 $\\odot$는 원소별 곱셈(element-wise multiplication)을 의미하고, $\\oplus$는 원소별 덧셈(element-wise addition)을 나타낸다.  \n","또 $x^{(t)}$은 타임 스텝 t에서 입력 데이터이고, $h^{(t-1)}$은 타임 스텝 t-1에서 은닉 유닛의 출력 이다.  \n","네 개의 상자는 시그모이드 함수($\\sigma$)나 하이퍼볼릭 탄젠트(tanh) 활성화 함수와 일련의 가중치로 표시된다. 이 상자는 입력에 대해 행렬-벡터 곱셈을 수행한 후 선형 조합된다.   \n","\n","LSTM 셀에는 **삭제 게이트**(forget gate), **입력 게이트**(input gate), **출력 게이트**(output gate)가 있다. "]},{"cell_type":"markdown","metadata":{"id":"uH6q_EEsz5Gy"},"source":["# 텐서플로로 시퀀스 모델링을 위한 RNN 구현"]},{"cell_type":"markdown","metadata":{"id":"zdZfJ9fiz5Gy"},"source":["## 첫 번째 프로젝트: IMDb 영화 리뷰의 감성 분석"]},{"cell_type":"markdown","metadata":{"id":"aDhA2boCz5Gy"},"source":["감성 분석을 위해 다대일(many-to-one) 구조의 다층 RNN을 구현해보자.  "]},{"cell_type":"markdown","metadata":{"id":"arShwNmEz5Gy"},"source":["#### 영화 리뷰 데이터 준비\n","8장의 전처리 단계에서 만든 정제된 데이터셋인 movie_data.csv 파일을 다시 사용."]},{"cell_type":"code","execution_count":13,"metadata":{"id":"vWhr9PBtz5Gz","executionInfo":{"status":"ok","timestamp":1669286520346,"user_tz":-540,"elapsed":1673,"user":{"displayName":"한현구","userId":"08987249905342132055"}}},"outputs":[],"source":["import tensorflow as tf\n","import tensorflow_datasets as tfds\n","import numpy as np\n","import pandas as pd"]},{"cell_type":"code","source":["# 코랩에서 실행하는 경우 다음 코드를 실행하세요.\n","!mkdir ../ch08\n","!wget https://github.com/rickiepark/python-machine-learning-book-3rd-edition/raw/master/ch08/movie_data.csv.gz -O ../ch08/movie_data.csv.gz"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sdeGtNhK0BU9","executionInfo":{"status":"ok","timestamp":1669286522026,"user_tz":-540,"elapsed":1693,"user":{"displayName":"한현구","userId":"08987249905342132055"}},"outputId":"262a88bd-24ba-4cf0-f411-fae1f55750f3"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["--2022-11-24 10:41:49--  https://github.com/rickiepark/python-machine-learning-book-3rd-edition/raw/master/ch08/movie_data.csv.gz\n","Resolving github.com (github.com)... 140.82.121.4\n","Connecting to github.com (github.com)|140.82.121.4|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://raw.githubusercontent.com/rickiepark/python-machine-learning-book-3rd-edition/master/ch08/movie_data.csv.gz [following]\n","--2022-11-24 10:41:49--  https://raw.githubusercontent.com/rickiepark/python-machine-learning-book-3rd-edition/master/ch08/movie_data.csv.gz\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.108.133, 185.199.110.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 26521894 (25M) [application/octet-stream]\n","Saving to: ‘../ch08/movie_data.csv.gz’\n","\n","../ch08/movie_data. 100%[===================>]  25.29M  --.-KB/s    in 0.1s    \n","\n","2022-11-24 10:41:51 (181 MB/s) - ‘../ch08/movie_data.csv.gz’ saved [26521894/26521894]\n","\n"]}]},{"cell_type":"code","source":["import os\n","import gzip\n","import shutil\n","\n","\n","with gzip.open('../ch08/movie_data.csv.gz', 'rb') as f_in, open('movie_data.csv', 'wb') as f_out:\n","    shutil.copyfileobj(f_in, f_out)"],"metadata":{"id":"Z5s3mJ-b0EdM","executionInfo":{"status":"ok","timestamp":1669286522941,"user_tz":-540,"elapsed":923,"user":{"displayName":"한현구","userId":"08987249905342132055"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"VbmPv45Yz5Gz","executionInfo":{"status":"ok","timestamp":1669286523971,"user_tz":-540,"elapsed":1034,"user":{"displayName":"한현구","userId":"08987249905342132055"}},"outputId":"1b27adbe-579d-4902-e2ad-b6d185f449f1"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                                  review  sentiment\n","49995  OK, lets start with the best. the building. al...          0\n","49996  The British 'heritage film' industry is out of...          0\n","49997  I don't even know where to begin on this one. ...          0\n","49998  Richard Tyler is a little boy who is scared of...          0\n","49999  I waited long to watch this movie. Also becaus...          1"],"text/html":["\n","  <div id=\"df-82d2dc9a-9fcc-4624-a718-6b6b69f6c7f2\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>review</th>\n","      <th>sentiment</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>49995</th>\n","      <td>OK, lets start with the best. the building. al...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>49996</th>\n","      <td>The British 'heritage film' industry is out of...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>49997</th>\n","      <td>I don't even know where to begin on this one. ...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>49998</th>\n","      <td>Richard Tyler is a little boy who is scared of...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>49999</th>\n","      <td>I waited long to watch this movie. Also becaus...</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-82d2dc9a-9fcc-4624-a718-6b6b69f6c7f2')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-82d2dc9a-9fcc-4624-a718-6b6b69f6c7f2 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-82d2dc9a-9fcc-4624-a718-6b6b69f6c7f2');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":16}],"source":["df = pd.read_csv('movie_data.csv', encoding='utf-8')\n","\n","df.tail()"]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hiJuAFCMz5Gz","executionInfo":{"status":"ok","timestamp":1669286524581,"user_tz":-540,"elapsed":615,"user":{"displayName":"한현구","userId":"08987249905342132055"}},"outputId":"0b327733-bd5f-4ffe-e474-4d1ad0c3e0aa"},"outputs":[{"output_type":"stream","name":"stdout","text":["b'In 1974, the teenager Martha Moxley (Maggie Grace)' 1\n","b'OK... so... I really like Kris Kristofferson and h' 0\n","b'***SPOILER*** Do not read this, if you think about' 0\n"]}],"source":["# 단계 1: 데이터셋 만들기\n","target = df.pop('sentiment')\n","\n","ds_raw = tf.data.Dataset.from_tensor_slices(\n","    (df.values, target.values))\n","\n","## 확인:\n","for ex in ds_raw.take(3):\n","    tf.print(ex[0].numpy()[0][:50], ex[1])"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"1OCF-RY7z5Gz","executionInfo":{"status":"ok","timestamp":1669286524583,"user_tz":-540,"elapsed":8,"user":{"displayName":"한현구","userId":"08987249905342132055"}}},"outputs":[],"source":["## 훈련/검증/테스트 분할\n","tf.random.set_seed(1)\n","\n","ds_raw = ds_raw.shuffle(\n","    50000, reshuffle_each_iteration=False)\n","\n","ds_raw_test = ds_raw.take(25000)\n","ds_raw_train_valid = ds_raw.skip(25000)\n","ds_raw_train = ds_raw_train_valid.take(20000)\n","ds_raw_valid = ds_raw_train_valid.skip(20000)"]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Y4p68IVkz5G0","executionInfo":{"status":"ok","timestamp":1669286531708,"user_tz":-540,"elapsed":7131,"user":{"displayName":"한현구","userId":"08987249905342132055"}},"outputId":"d2b3b26f-d96c-4751-875c-a70b66949bfa"},"outputs":[{"output_type":"stream","name":"stdout","text":["어휘 사전 크기: 87007\n"]}],"source":["## 단계 2: 고유 토큰(단어) 찾기\n","from collections import Counter\n","\n","tokenizer = tfds.deprecated.text.Tokenizer()\n","token_counts = Counter()\n","\n","for example in ds_raw_train:\n","    tokens = tokenizer.tokenize(example[0].numpy()[0])\n","    token_counts.update(tokens)\n","    \n","print('어휘 사전 크기:', len(token_counts))"]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EKbGZJpaz5G0","executionInfo":{"status":"ok","timestamp":1669286531709,"user_tz":-540,"elapsed":36,"user":{"displayName":"한현구","userId":"08987249905342132055"}},"outputId":"0f422935-98e7-4701-eb83-6337407d37b4"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["[232, 9, 270, 1123]"]},"metadata":{},"execution_count":20}],"source":["## 단계 3: 고유 토큰을 정수로 인코딩하기\n","encoder = tfds.deprecated.text.TokenTextEncoder(token_counts)\n","\n","example_str = 'This is an example!'\n","encoder.encode(example_str)"]},{"cell_type":"markdown","metadata":{"id":"zpBPH6jBz5G0"},"source":["검증 데이터와 테스트 데이터에 있는 토큰이 훈련 데이터에 없다면 매핑되지 않을 수 있다.  \n","q개의 토큰이 있고 이전에 본 적이 없으며 `token_counts`에 포함되지 않은 모든 토큰은 정수 q+1에 할당된다.  \n","다른 말로 하면 인덱스 q+1이 알려지지 않은 단어를 위해 예약된다. 예약된 또 다른 값은 정수 0이다. 시퀀스 길이를 조절하기 위한 용도로 사용한다.  \n","\n","데이터셋 객체의 `map()` 메서드를 사용하여 다른 변환을 적용하듯이 데이터셋에 있는 각 텍스트를 변환할 수 있다. 하지만 여기에는 작은 문제가 있다. 텍스트 데이터가 텐서 객체에 들어가 있어 즉시 실행 모드에서 텐서의 `numpy()` 메서드로 참조할 수 있다. 하지만 `map()` 메서드로 변환하는 동안에는 즉시 실행이 비활성화된다. 이 문제를 해결하기 위해 두 개의 함수를 정의한다. 첫 번째 함수는 즉시 실행 모드가 활성화된 것처럼 입력 텐서를 다룬다."]},{"cell_type":"code","execution_count":21,"metadata":{"id":"H6-noIpXz5G0","executionInfo":{"status":"ok","timestamp":1669286531710,"user_tz":-540,"elapsed":32,"user":{"displayName":"한현구","userId":"08987249905342132055"}}},"outputs":[],"source":["## 단계 3-A: 변환 함수 정의하기\n","def encode(text_tensor, label):\n","    text = text_tensor.numpy()[0]\n","    encoded_text = encoder.encode(text)\n","    return encoded_text, label"]},{"cell_type":"markdown","metadata":{"id":"902GUQn6z5G1"},"source":["두 번째 함수에서 첫 번째 함수를 `tf.py_function` 으로 감싸서 `map()` 메서드에서 사용할 수 있는 텐서플로 연산으로 변환한다. "]},{"cell_type":"code","execution_count":22,"metadata":{"id":"kQa7R8ZDz5G1","executionInfo":{"status":"ok","timestamp":1669286531710,"user_tz":-540,"elapsed":31,"user":{"displayName":"한현구","userId":"08987249905342132055"}}},"outputs":[],"source":["## 단계 3-B: 인코딩 함수를 텐서플로 연산으로 감싸기\n","def encode_map_fn(text, label):\n","    return tf.py_function(encode, inp=[text, label], \n","                          Tout=(tf.int64, tf.int64))"]},{"cell_type":"code","execution_count":23,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JUzTRuKdz5G1","executionInfo":{"status":"ok","timestamp":1669286532691,"user_tz":-540,"elapsed":1012,"user":{"displayName":"한현구","userId":"08987249905342132055"}},"outputId":"5b57c13c-1944-4be3-fa15-d2463e7666ec"},"outputs":[{"output_type":"stream","name":"stdout","text":["시퀀스 길이: (24,)\n","시퀀스 길이: (179,)\n","시퀀스 길이: (262,)\n","시퀀스 길이: (535,)\n","시퀀스 길이: (130,)\n"]},{"output_type":"execute_result","data":{"text/plain":["(<tf.Tensor: shape=(130,), dtype=int64, numpy=\n"," array([  579,  1296,    32,   425,    40,   763,  9267,    65,   280,\n","          308,     6,   481,   155,   473,     2,     3,   684,     9,\n","          781,   176,   959,   730,  3917,    67,  9905,    13,   277,\n","           24,    35,   371, 16368,     6,    14, 17231,    29,   187,\n","         1651,   489,   503,   480,   143,    32,   270,  5851,  2402,\n","           13,  3592,  3443,   425,  3313,   256,   257,  1577,   117,\n","            8,   698,   270,   564,    56,     8,    42,  7517,  2629,\n","          820,    25,    60,    79,   343,    32,   645,    14,   528,\n","          241,    32,  1980,     8,    56,     8,    42,  1364,   573,\n","         5183,    43,    12,  3870,    32,   312,   642,   251,  1401,\n","        17232,     8,   698,   257,   750,     2,     9,    76,   235,\n","            8,    42,   235,   840,   666,   258, 17233,   419,    32,\n","        17234,   585,   420,   840,    25,    40,    13,    14,   198,\n","          266,   623,   173,   179,  4103,   216,    25,   616, 14185,\n","          186,    35, 16250,   120])>,\n"," <tf.Tensor: shape=(), dtype=int64, numpy=0>)"]},"metadata":{},"execution_count":23}],"source":["ds_train = ds_raw_train.map(encode_map_fn)\n","ds_valid = ds_raw_valid.map(encode_map_fn)\n","ds_test = ds_raw_test.map(encode_map_fn)\n","\n","tf.random.set_seed(1)\n","for example in ds_train.shuffle(1000).take(5):\n","    print('시퀀스 길이:', example[0].shape)\n","    \n","example"]},{"cell_type":"markdown","metadata":{"id":"fgrgV4KJz5G1"},"source":["지금까지 단어 시퀀스를 정수 시퀀스로 변환했다. 하지만 여전히 해결할 문제가 하나 있다. 시퀀스 길이가 다르다.  \n","일반적으로 RNN은 다른 길이의 시퀸스를 다룰 수 있지만 미니 배치에 있는 시퀀스는 효율적으로 텐서에 저장하기 위해 동일한 길이가 되어야 한다.  \n","\n","크기가 다른 원소를 가진 데이터셋을 미니 배치로 나누기 위해 텐서플로는 `padded_batch()` 메서드를 제공한다. 이 메서드는 하나의 배치에 포함되는 모든 원소를 자동으로 0으로 패딩하여 배치에 있는 모든 시퀀스가 동일한 길이가 되도록 만든다. "]},{"cell_type":"code","execution_count":24,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AmY7aCBMz5G1","executionInfo":{"status":"ok","timestamp":1669286533188,"user_tz":-540,"elapsed":502,"user":{"displayName":"한현구","userId":"08987249905342132055"}},"outputId":"6c1818b3-d6ff-40ce-fc66-406ffd60fb39"},"outputs":[{"output_type":"stream","name":"stdout","text":["개별 샘플 크기: (119,)\n","개별 샘플 크기: (688,)\n","개별 샘플 크기: (308,)\n","개별 샘플 크기: (204,)\n","개별 샘플 크기: (326,)\n","개별 샘플 크기: (240,)\n","개별 샘플 크기: (127,)\n","개별 샘플 크기: (453,)\n","배치 차원: (4, 688)\n","배치 차원: (4, 453)\n"]}],"source":["## 일부 데이터 추출하기\n","ds_subset = ds_train.take(8)\n","for example in ds_subset:\n","    print('개별 샘플 크기:', example[0].shape)\n","\n","## 배치 데이터 만들기\n","ds_batched = ds_subset.padded_batch(\n","    4, padded_shapes=([-1], []))\n","\n","for batch in ds_batched:\n","    print('배치 차원:', batch[0].shape)"]},{"cell_type":"markdown","metadata":{"id":"A89fTchOz5G2"},"source":["출력된 텐서 크기에서 알 수 있듯이 첫 번째 배치의 열 개수(즉, .shape[1])는 688이다. 처음 네 개의 샘플이 하나의 배치가 되었고 이 샘플 중에서 가장 큰 크기를 사용했다.  \n","다시 말하면 이 배치에 있는 세 개의 다른 샘플을 이 크기에 맞도록 필요한 만큼 패딩을 추가했다. 비슷하게 두 번째 배치의 열 크기는 다음 네 개의 샘플 중 가장 큰 크기인 453이다. 여기서도 최대 길이보다 작은 다른 샘플에 패딩을 추가했다.  \n","\n","세 개의 데이터셋을 모두 배치 크기 32의 미니 배치로 나눈다."]},{"cell_type":"code","execution_count":25,"metadata":{"id":"QiPRFy6Tz5G2","executionInfo":{"status":"ok","timestamp":1669286533190,"user_tz":-540,"elapsed":42,"user":{"displayName":"한현구","userId":"08987249905342132055"}}},"outputs":[],"source":["## 배치 데이터 만들기\n","train_data = ds_train.padded_batch(\n","    32, padded_shapes=([-1],[]))\n","\n","valid_data = ds_valid.padded_batch(\n","    32, padded_shapes=([-1],[]))\n","\n","test_data = ds_test.padded_batch(\n","    32, padded_shapes=([-1],[]))"]},{"cell_type":"markdown","metadata":{"id":"gfUarCgHz5G2"},"source":["이제 데이터가 이어지는 절에서 구현할 RNN 모델에 적합한 포맷이 되었다. "]},{"cell_type":"markdown","metadata":{"id":"_q0PvXfWz5G2"},"source":["#### 문장 인코딩을 위한 임베딩 층 \n","이전의 데이터 준비 단계에서 동일한 길이의 시퀀스르 생성했다. 이 시퀀스의 원소는 고유한 단어의 인덱스에 해당하는 정수이다. 이런 단어 인덱스를 입력 특성으로 변환하는 몇 가지 방법이 있다.  \n","간단하게 원-핫 인코딩을 적용하여 인덱스를 0 또는 1로 이루어진 벡터로 변환할 수 있다. 각 단어는 전체 데이터셋의 고유한 단어의 수에 해당하는 크기를 가진 벡터로 변환된다.  \n","고유한 단어의 수(어휘 사전의 크기)가 $10^{4}-10^5$ 단위가 될 수 있으며 입력 특성의 개수도 마찬가지이다. 이렇 게 많은 특성에서 훈련된 모델은 **차원의 저주**(curse of dimensionality)로 인한 영향을 받는다. 또 하나를 제외하고 모든 원소가 0이므로 특성 벡터가 매우 희소해진다.  \n","\n","좀 더 고급스러운 방법은 각 단어를 실수 값을 가진 고정된 길이의 벡터로 변환하는 것이다. 원-핫 인코딩과 달리 고정된 길이의 벡터를 사용하여 무한히 많은 실수를 표현할 수 있다.  \n","\n","**임베딩**(embedding)이라고 하는 특성 학습 기법을 사용하여 데이터셋에 있는 단어를 표현하는 데 중요한 특성을 자동으로 학습할 수 있다. 고유한 단어의 수를 $x_{words}$라고 하면 고유한 단어의 수보다 훨씬 작게 임베딩 벡터(또는 임베딩 차원) 크기를 선택하여 전체 어휘를 특성으로 나타낸다.  \n","\n","원-핫 인코딩에 비해 임베딩의 장점은 다음과 같다.  \n","- 특성 공간의 차원이 축소되므로 차원의 저주로 인한 영향을 감소시킨다.  \n","- 신경망에서 임베딩 층이 최적화되기 때문에 중요한 특성이 추출된다."]},{"cell_type":"code","execution_count":26,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":598},"id":"B6GkLgtVz5G2","executionInfo":{"status":"ok","timestamp":1669286533192,"user_tz":-540,"elapsed":43,"user":{"displayName":"한현구","userId":"08987249905342132055"}},"outputId":"ab59afa3-5ea4-4874-9b04-21eca6e62c8d"},"outputs":[{"output_type":"execute_result","data":{"text/html":["<img src=\"https://git.io/JLdV0\" width=\"700\"/>"],"text/plain":["<IPython.core.display.Image object>"]},"metadata":{},"execution_count":26}],"source":["Image(url='https://git.io/JLdV0', width=700)"]},{"cell_type":"markdown","metadata":{"id":"cYAuD0mXz5G3"},"source":["n+2 크기(토큰 개수 n에 패딩을 위해 예약된 인덱스 0과 토큰 집합에 없는 단어를 위해 예약된 인덱스 n+1이 추가)의 토큰 집합이 주어지면 $(n+2)\\times embedding\\_dim$크기의 임베딩 행렬이 만들어진다. 이 행렬의 행은 토큰에 연관된 수치 특성을 표현한다. "]},{"cell_type":"code","execution_count":27,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9vOPkaqOz5G3","executionInfo":{"status":"ok","timestamp":1669286533194,"user_tz":-540,"elapsed":42,"user":{"displayName":"한현구","userId":"08987249905342132055"}},"outputId":"b4c2267e-2151-4d4e-8e60-6cd2aab0d825"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," embed-layer (Embedding)     (None, 20, 6)             600       \n","                                                                 \n","=================================================================\n","Total params: 600\n","Trainable params: 600\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}],"source":["from tensorflow.keras.layers import Embedding\n","\n","\n","model = tf.keras.Sequential()\n","\n","model.add(Embedding(input_dim=100,\n","                    output_dim=6,\n","                    input_length=20,\n","                    name='embed-layer'))\n","\n","model.summary()"]},{"cell_type":"markdown","metadata":{"id":"QM9OnbFEz5G3"},"source":["이 모델의 입력(임베딩 층)은 $batchsize \\times input\\_length$ 차원을 가진 랭크 2여야 한다. 여기서 $input\\_length$는 시퀀스 길이이다.  \n","출력 차원은 $batchsize \\times input\\_length \\times embedding\\_dim$이다. $embedding\\_dim$은 임베딩 특성의 크기이다. \n"]},{"cell_type":"markdown","metadata":{"id":"Z8loH6AKz5G3"},"source":["#### RNN 모델 만들기  \n","순환 층에는 다음과 같은 클래스를 사용할 수 있다.  \n","- SimpleRNN: 완전 연결 순환 층인 기본 RNN  \n","- LSTM: 긴 의존성을 감지할 수 있는 LSTM RNN  \n","- GRU: LTSM의 대안인 GRU 유닛을 사용한 순환 층"]},{"cell_type":"code","execution_count":28,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Fyjoe7KSz5G4","executionInfo":{"status":"ok","timestamp":1669286533677,"user_tz":-540,"elapsed":510,"user":{"displayName":"한현구","userId":"08987249905342132055"}},"outputId":"c96ed739-23df-4bdb-ce93-bcba355c41ec"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," embedding (Embedding)       (None, None, 32)          32000     \n","                                                                 \n"," simple_rnn_1 (SimpleRNN)    (None, None, 32)          2080      \n","                                                                 \n"," simple_rnn_2 (SimpleRNN)    (None, 32)                2080      \n","                                                                 \n"," dense (Dense)               (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 36,193\n","Trainable params: 36,193\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}],"source":["## SimpleRNN 층으로 RNN 모델 만들기\n","from tensorflow.keras import Sequential\n","from tensorflow.keras.layers import Embedding\n","from tensorflow.keras.layers import SimpleRNN\n","from tensorflow.keras.layers import Dense\n","\n","model = Sequential()\n","model.add(Embedding(1000, 32))\n","model.add(SimpleRNN(32, return_sequences=True))\n","model.add(SimpleRNN(32))\n","model.add(Dense(1))\n","model.summary()"]},{"cell_type":"code","execution_count":29,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zNK2KUMnz5G4","executionInfo":{"status":"ok","timestamp":1669286534450,"user_tz":-540,"elapsed":777,"user":{"displayName":"한현구","userId":"08987249905342132055"}},"outputId":"a7f46fc9-6b9f-4694-d802-18a61811e132"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_2\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," embedding_1 (Embedding)     (None, None, 32)          320000    \n","                                                                 \n"," lstm (LSTM)                 (None, None, 32)          8320      \n","                                                                 \n"," lstm_1 (LSTM)               (None, 32)                8320      \n","                                                                 \n"," dense_1 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 336,673\n","Trainable params: 336,673\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}],"source":["## LSTM 층으로 RNN 모델 만들기\n","from tensorflow.keras.layers import LSTM\n","\n","\n","model = Sequential()\n","model.add(Embedding(10000, 32))\n","model.add(LSTM(32, return_sequences=True))\n","model.add(LSTM(32))\n","model.add(Dense(1))\n","model.summary()"]},{"cell_type":"code","execution_count":30,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4uXLF2dqz5G4","executionInfo":{"status":"ok","timestamp":1669286534452,"user_tz":-540,"elapsed":20,"user":{"displayName":"한현구","userId":"08987249905342132055"}},"outputId":"4675c83d-12d6-4668-bae4-bf4c122fbaaf"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_3\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," embedding_2 (Embedding)     (None, None, 32)          320000    \n","                                                                 \n"," gru (GRU)                   (None, None, 32)          6336      \n","                                                                 \n"," gru_1 (GRU)                 (None, 32)                6336      \n","                                                                 \n"," dense_2 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 332,705\n","Trainable params: 332,705\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}],"source":["## GRU 층으로 RNN 모델 만들기\n","from tensorflow.keras.layers import GRU\n","\n","model = Sequential()\n","model.add(Embedding(10000, 32))\n","model.add(GRU(32, return_sequences=True))\n","model.add(GRU(32))\n","model.add(Dense(1))\n","model.summary()"]},{"cell_type":"markdown","metadata":{"id":"lNKtS54Gz5G4"},"source":["#### 감성 분석 작업을 위한 RNN 모델 만들기\n","시퀀스 길이가 길기 때문에 길게 미치는 영향을 감지하기 위해 LSTM 층을 사용한다. 또한, `Bidirectional` 클래스로 LSTM 층을 감싼다.  \n","이 층은 입력 시퀀스를 처음부터 끝까지 그리고 끝에서 처음까지 양방향으로 순환 층을 통과하도록 한다. "]},{"cell_type":"code","execution_count":31,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MUysEeJQz5G4","executionInfo":{"status":"ok","timestamp":1669287156955,"user_tz":-540,"elapsed":622514,"user":{"displayName":"한현구","userId":"08987249905342132055"}},"outputId":"e3221cef-6b27-47b0-c762-1e6937f734c9"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_4\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," embed-layer (Embedding)     (None, None, 20)          1740180   \n","                                                                 \n"," bidir-lstm (Bidirectional)  (None, 128)               43520     \n","                                                                 \n"," dense_3 (Dense)             (None, 64)                8256      \n","                                                                 \n"," dense_4 (Dense)             (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 1,792,021\n","Trainable params: 1,792,021\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","625/625 [==============================] - 62s 90ms/step - loss: 0.4990 - accuracy: 0.7466 - val_loss: 0.3863 - val_accuracy: 0.8594\n","Epoch 2/10\n","625/625 [==============================] - 54s 86ms/step - loss: 0.2270 - accuracy: 0.9164 - val_loss: 0.3571 - val_accuracy: 0.8700\n","Epoch 3/10\n","625/625 [==============================] - 58s 92ms/step - loss: 0.1779 - accuracy: 0.9389 - val_loss: 0.5080 - val_accuracy: 0.8538\n","Epoch 4/10\n","625/625 [==============================] - 55s 88ms/step - loss: 0.0980 - accuracy: 0.9668 - val_loss: 0.4900 - val_accuracy: 0.8144\n","Epoch 5/10\n","625/625 [==============================] - 58s 93ms/step - loss: 0.0766 - accuracy: 0.9732 - val_loss: 0.5836 - val_accuracy: 0.8564\n","Epoch 6/10\n","625/625 [==============================] - 56s 90ms/step - loss: 0.0539 - accuracy: 0.9833 - val_loss: 0.7519 - val_accuracy: 0.8202\n","Epoch 7/10\n","625/625 [==============================] - 58s 92ms/step - loss: 0.0725 - accuracy: 0.9744 - val_loss: 0.6116 - val_accuracy: 0.7754\n","Epoch 8/10\n","625/625 [==============================] - 60s 96ms/step - loss: 0.1153 - accuracy: 0.9571 - val_loss: 0.6703 - val_accuracy: 0.8400\n","Epoch 9/10\n","625/625 [==============================] - 58s 93ms/step - loss: 0.0306 - accuracy: 0.9910 - val_loss: 0.7013 - val_accuracy: 0.8360\n","Epoch 10/10\n","625/625 [==============================] - 56s 89ms/step - loss: 0.0139 - accuracy: 0.9956 - val_loss: 0.9625 - val_accuracy: 0.8362\n","782/782 [==============================] - 47s 60ms/step - loss: 0.9366 - accuracy: 0.8396\n","테스트 정확도: 83.96%\n"]}],"source":["embedding_dim = 20\n","vocab_size = len(token_counts) + 2\n","\n","tf.random.set_seed(1)\n","\n","## 모델 생성\n","bi_lstm_model = tf.keras.Sequential([\n","    tf.keras.layers.Embedding(\n","        input_dim=vocab_size,\n","        output_dim=embedding_dim,\n","        name='embed-layer'),\n","    \n","    tf.keras.layers.Bidirectional(\n","        tf.keras.layers.LSTM(64, name='lstm-layer'),\n","        name='bidir-lstm'), \n","\n","    tf.keras.layers.Dense(64, activation='relu'),\n","    \n","    tf.keras.layers.Dense(1, activation='sigmoid')\n","])\n","\n","bi_lstm_model.summary()\n","\n","## 컴파일과 훈련:\n","bi_lstm_model.compile(\n","    optimizer=tf.keras.optimizers.Adam(1e-3),\n","    loss=tf.keras.losses.BinaryCrossentropy(from_logits=False),\n","    metrics=['accuracy'])\n","\n","history = bi_lstm_model.fit(\n","    train_data, \n","    validation_data=valid_data, \n","    epochs=10)\n","\n","## 테스트 데이터에서 평가\n","test_results= bi_lstm_model.evaluate(test_data)\n","print('테스트 정확도: {:.2f}%'.format(test_results[1]*100))"]},{"cell_type":"code","source":["if not os.path.exists('models'):\n","    os.mkdir('models')\n","\n","\n","bi_lstm_model.save('models/Bidir-LSTM-full-length-seq.h5')"],"metadata":{"id":"m5YBh5Mm5QOZ","executionInfo":{"status":"ok","timestamp":1669287156956,"user_tz":-540,"elapsed":14,"user":{"displayName":"한현구","userId":"08987249905342132055"}}},"execution_count":32,"outputs":[]},{"cell_type":"markdown","source":["SimpleRNN과 같은 다른 종류의 순환 층을 사용할 수도 있다.  \n","일반적인 순환 층으로 만든 모델은 좋은 예측 성능을 달성하지 못한다. 예를 들어 이전 코드에서 양방향 LSTM 층을 단방향 SimpleRNN 층으로 바꾸고 전체 길이를 사용한 시퀀스로 모델을 훈련하면 훈련하는 동안 손실이 전혀 감소하지 않는다. 이 데이터셋에 있는 시퀀스가 너무 길기 때문이다. SimpleRNN 층을 사용한 모델은 장기간 의존성을 학습할 수 없고 그레이디언트 감소나 폭주로 인한 영향을 받는다.  \n","\n","SimpleRNN으로 이 데이터셋에서 납득할 수 있는 수준의 예측 성능을 얻으려면 시퀀스 길이를 줄여야 한다.  \n","영화 리뷰의 마지막 문장에 감성에 관한 정보가 많이 담겨 있다고 가정할 수 있다. 따라서 각 리뷰의 마지막 부분에만 초점을 맞추어 보자. `preprocess_datasets()` 라는 헬펌 함수를 만들어 전처리 단계 2~4를 연결한다.  \n","이 함수의 매개변수는 각 리뷰에서 얼마나 많은 토큰을 사용할지 결정하는 `max_seq_length`이다. 예를 들어 `max_seq_length=None`으로 지정하면 이전처럼 전체 길이의 시퀀스가 사용된다. "],"metadata":{"id":"h_Mc-7e404UT"}},{"cell_type":"markdown","source":["#### 짧은 시퀀스에 SimpleRNN 적용하기"],"metadata":{"id":"AH9bcWkb6c6g"}},{"cell_type":"code","source":["def preprocess_datasets(\n","    ds_raw_train, \n","    ds_raw_valid, \n","    ds_raw_test,\n","    max_seq_length=None,\n","    batch_size=32):\n","    \n","    ## 단계 1: (데이터셋 만들기 이미 완료)\n","    ## 단계 2: 고유 토큰 찾기\n","    tokenizer = tfds.deprecated.text.Tokenizer()\n","    token_counts = Counter()\n","\n","    for example in ds_raw_train:\n","        tokens = tokenizer.tokenize(example[0].numpy()[0])\n","        if max_seq_length is not None:\n","            tokens = tokens[-max_seq_length:]\n","        token_counts.update(tokens)\n","\n","    print('어휘 사전 크기:', len(token_counts))\n","\n","\n","    ## 단계 3: 텍스트 인코딩하기\n","    encoder = tfds.deprecated.text.TokenTextEncoder(token_counts)\n","    def encode(text_tensor, label):\n","        text = text_tensor.numpy()[0]\n","        encoded_text = encoder.encode(text)\n","        if max_seq_length is not None:\n","            encoded_text = encoded_text[-max_seq_length:]\n","        return encoded_text, label\n","\n","    def encode_map_fn(text, label):\n","        return tf.py_function(encode, inp=[text, label], \n","                              Tout=(tf.int64, tf.int64))\n","\n","    ds_train = ds_raw_train.map(encode_map_fn)\n","    ds_valid = ds_raw_valid.map(encode_map_fn)\n","    ds_test = ds_raw_test.map(encode_map_fn)\n","\n","    ## 단계 4: 배치 데이터 만들기\n","    train_data = ds_train.padded_batch(\n","        batch_size, padded_shapes=([-1],[]))\n","\n","    valid_data = ds_valid.padded_batch(\n","        batch_size, padded_shapes=([-1],[]))\n","\n","    test_data = ds_test.padded_batch(\n","        batch_size, padded_shapes=([-1],[]))\n","\n","    return (train_data, valid_data, \n","            test_data, len(token_counts))"],"metadata":{"id":"c05heASu5mVV","executionInfo":{"status":"ok","timestamp":1669287156956,"user_tz":-540,"elapsed":11,"user":{"displayName":"한현구","userId":"08987249905342132055"}}},"execution_count":33,"outputs":[]},{"cell_type":"code","source":["def build_rnn_model(embedding_dim, vocab_size,\n","                    recurrent_type='SimpleRNN',\n","                    n_recurrent_units=64,\n","                    n_recurrent_layers=1,\n","                    bidirectional=True):\n","\n","    tf.random.set_seed(1)\n","\n","    # 모델 생성\n","    model = tf.keras.Sequential()\n","    \n","    model.add(\n","        Embedding(\n","            input_dim=vocab_size,\n","            output_dim=embedding_dim,\n","            name='embed-layer')\n","    )\n","    \n","    for i in range(n_recurrent_layers):\n","        return_sequences = (i < n_recurrent_layers-1)\n","            \n","        if recurrent_type == 'SimpleRNN':\n","            recurrent_layer = SimpleRNN(\n","                units=n_recurrent_units, \n","                return_sequences=return_sequences,\n","                name='simprnn-layer-{}'.format(i))\n","        elif recurrent_type == 'LSTM':\n","            recurrent_layer = LSTM(\n","                units=n_recurrent_units, \n","                return_sequences=return_sequences,\n","                name='lstm-layer-{}'.format(i))\n","        elif recurrent_type == 'GRU':\n","            recurrent_layer = GRU(\n","                units=n_recurrent_units, \n","                return_sequences=return_sequences,\n","                name='gru-layer-{}'.format(i))\n","        \n","        if bidirectional:\n","            recurrent_layer = Bidirectional(\n","                recurrent_layer, name='bidir-'+recurrent_layer.name)\n","            \n","        model.add(recurrent_layer)\n","\n","    model.add(tf.keras.layers.Dense(64, activation='relu'))\n","    model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n","    \n","    return model"],"metadata":{"id":"sTWmIWM63nRV","executionInfo":{"status":"ok","timestamp":1669287156957,"user_tz":-540,"elapsed":11,"user":{"displayName":"한현구","userId":"08987249905342132055"}}},"execution_count":34,"outputs":[]},{"cell_type":"code","source":["from tensorflow.keras.layers import Bidirectional\n","\n","\n","batch_size = 32\n","embedding_dim = 20\n","max_seq_length = 100\n","\n","train_data, valid_data, test_data, n = preprocess_datasets(\n","    ds_raw_train, ds_raw_valid, ds_raw_test, \n","    max_seq_length=max_seq_length, \n","    batch_size=batch_size\n",")\n","\n","\n","vocab_size = n + 2\n","\n","rnn_model = build_rnn_model(\n","    embedding_dim, vocab_size,\n","    recurrent_type='SimpleRNN', \n","    n_recurrent_units=64,\n","    n_recurrent_layers=1,\n","    bidirectional=True)\n","\n","rnn_model.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c1wD2zPI5fm7","executionInfo":{"status":"ok","timestamp":1669287163073,"user_tz":-540,"elapsed":6126,"user":{"displayName":"한현구","userId":"08987249905342132055"}},"outputId":"cf813bb1-adef-467e-b13f-f71b4efeddff"},"execution_count":35,"outputs":[{"output_type":"stream","name":"stdout","text":["어휘 사전 크기: 58063\n","Model: \"sequential_5\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," embed-layer (Embedding)     (None, None, 20)          1161300   \n","                                                                 \n"," bidir-simprnn-layer-0 (Bidi  (None, 128)              10880     \n"," rectional)                                                      \n","                                                                 \n"," dense_5 (Dense)             (None, 64)                8256      \n","                                                                 \n"," dense_6 (Dense)             (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 1,180,501\n","Trainable params: 1,180,501\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":["rnn_model.compile(optimizer=tf.keras.optimizers.Adam(1e-3),\n","                  loss=tf.keras.losses.BinaryCrossentropy(from_logits=False),\n","                  metrics=['accuracy'])\n","\n","\n","history = rnn_model.fit(\n","    train_data, \n","    validation_data=valid_data, \n","    epochs=10)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UxNkEMRG6u8l","outputId":"9a3c6689-83cb-442d-b313-837004119d9c","executionInfo":{"status":"ok","timestamp":1669288506547,"user_tz":-540,"elapsed":1343480,"user":{"displayName":"한현구","userId":"08987249905342132055"}}},"execution_count":36,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","625/625 [==============================] - 147s 231ms/step - loss: 0.7001 - accuracy: 0.5069 - val_loss: 0.6920 - val_accuracy: 0.5194\n","Epoch 2/10\n","625/625 [==============================] - 146s 234ms/step - loss: 0.6705 - accuracy: 0.5681 - val_loss: 0.5748 - val_accuracy: 0.7288\n","Epoch 3/10\n","625/625 [==============================] - 138s 221ms/step - loss: 0.5379 - accuracy: 0.7278 - val_loss: 0.5316 - val_accuracy: 0.7792\n","Epoch 4/10\n","625/625 [==============================] - 140s 224ms/step - loss: 0.3444 - accuracy: 0.8539 - val_loss: 0.4213 - val_accuracy: 0.8198\n","Epoch 5/10\n","625/625 [==============================] - 132s 211ms/step - loss: 0.1975 - accuracy: 0.9271 - val_loss: 0.5590 - val_accuracy: 0.7926\n","Epoch 6/10\n","625/625 [==============================] - 125s 200ms/step - loss: 0.1276 - accuracy: 0.9553 - val_loss: 0.5759 - val_accuracy: 0.8220\n","Epoch 7/10\n","625/625 [==============================] - 130s 208ms/step - loss: 0.0638 - accuracy: 0.9798 - val_loss: 0.7014 - val_accuracy: 0.8156\n","Epoch 8/10\n","625/625 [==============================] - 133s 212ms/step - loss: 0.1772 - accuracy: 0.9308 - val_loss: 0.6038 - val_accuracy: 0.7636\n","Epoch 9/10\n","625/625 [==============================] - 127s 202ms/step - loss: 0.0797 - accuracy: 0.9725 - val_loss: 0.7780 - val_accuracy: 0.8216\n","Epoch 10/10\n","625/625 [==============================] - 125s 200ms/step - loss: 0.0548 - accuracy: 0.9811 - val_loss: 0.8886 - val_accuracy: 0.8180\n"]}]},{"cell_type":"code","source":["results = rnn_model.evaluate(test_data)"],"metadata":{"id":"gHsNmUgK6x2j","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1669288537692,"user_tz":-540,"elapsed":31183,"user":{"displayName":"한현구","userId":"08987249905342132055"}},"outputId":"d10095be-9644-45bd-ac23-27a302acf5e1"},"execution_count":37,"outputs":[{"output_type":"stream","name":"stdout","text":["782/782 [==============================] - 31s 40ms/step - loss: 0.8691 - accuracy: 0.8241\n"]}]},{"cell_type":"code","source":["print('테스트 정확도: {:.2f}%'.format(results[1]*100))"],"metadata":{"id":"QO4KTQPa6zE6","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1669288537693,"user_tz":-540,"elapsed":52,"user":{"displayName":"한현구","userId":"08987249905342132055"}},"outputId":"aafc467e-ee2c-4e10-b0be-5a0ee612efcb"},"execution_count":38,"outputs":[{"output_type":"stream","name":"stdout","text":["테스트 정확도: 82.41%\n"]}]},{"cell_type":"markdown","source":["### 연습 문제:  \n","#### 전체 길이를 사용한 시퀀스에 단방향 SimpleRNN 적용하기"],"metadata":{"id":"5tsgpfPhLX6-"}},{"cell_type":"code","source":["batch_size = 32\n","embedding_dim = 20\n","max_seq_length = None\n","\n","train_data, valid_data, test_data, n = preprocess_datasets(\n","    ds_raw_train, ds_raw_valid, ds_raw_test, \n","    max_seq_length=max_seq_length, \n","    batch_size=batch_size\n",")\n","\n","\n","vocab_size = n + 2\n","\n","rnn_model = build_rnn_model(\n","    embedding_dim, vocab_size,\n","    recurrent_type='SimpleRNN', \n","    n_recurrent_units=64,\n","    n_recurrent_layers=1,\n","    bidirectional=False)\n","\n","rnn_model.summary()"],"metadata":{"id":"ex5Gv3eED9ce","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1669288544481,"user_tz":-540,"elapsed":6833,"user":{"displayName":"한현구","userId":"08987249905342132055"}},"outputId":"7ca4ab39-98b2-4232-9677-8c105322604a"},"execution_count":39,"outputs":[{"output_type":"stream","name":"stdout","text":["어휘 사전 크기: 87007\n","Model: \"sequential_6\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," embed-layer (Embedding)     (None, None, 20)          1740180   \n","                                                                 \n"," simprnn-layer-0 (SimpleRNN)  (None, 64)               5440      \n","                                                                 \n"," dense_7 (Dense)             (None, 64)                4160      \n","                                                                 \n"," dense_8 (Dense)             (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 1,749,845\n","Trainable params: 1,749,845\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":["rnn_model.compile(optimizer=tf.keras.optimizers.Adam(1e-3),\n","                  loss=tf.keras.losses.BinaryCrossentropy(from_logits=False),\n","                  metrics=['accuracy'])\n","\n","history = rnn_model.fit(\n","    train_data, \n","    validation_data=valid_data, \n","    epochs=10)"],"metadata":{"id":"c7Jf3uliLhpB","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1669293982887,"user_tz":-540,"elapsed":5438412,"user":{"displayName":"한현구","userId":"08987249905342132055"}},"outputId":"82bcea81-858e-4855-f2cd-76d65978fe07"},"execution_count":40,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","625/625 [==============================] - 559s 892ms/step - loss: 0.7000 - accuracy: 0.5041 - val_loss: 0.7149 - val_accuracy: 0.5140\n","Epoch 2/10\n","625/625 [==============================] - 549s 879ms/step - loss: 0.7020 - accuracy: 0.4983 - val_loss: 0.7042 - val_accuracy: 0.4916\n","Epoch 3/10\n","625/625 [==============================] - 544s 871ms/step - loss: 0.6983 - accuracy: 0.4985 - val_loss: 0.7046 - val_accuracy: 0.4948\n","Epoch 4/10\n","625/625 [==============================] - 540s 865ms/step - loss: 0.6967 - accuracy: 0.5034 - val_loss: 0.7011 - val_accuracy: 0.4934\n","Epoch 5/10\n","625/625 [==============================] - 543s 870ms/step - loss: 0.6956 - accuracy: 0.5044 - val_loss: 0.6976 - val_accuracy: 0.4994\n","Epoch 6/10\n","625/625 [==============================] - 537s 859ms/step - loss: 0.6950 - accuracy: 0.5024 - val_loss: 0.6972 - val_accuracy: 0.4966\n","Epoch 7/10\n","625/625 [==============================] - 544s 870ms/step - loss: 0.6944 - accuracy: 0.5008 - val_loss: 0.6955 - val_accuracy: 0.4994\n","Epoch 8/10\n","625/625 [==============================] - 542s 867ms/step - loss: 0.6941 - accuracy: 0.5034 - val_loss: 0.6944 - val_accuracy: 0.5044\n","Epoch 9/10\n","625/625 [==============================] - 542s 867ms/step - loss: 0.6938 - accuracy: 0.5038 - val_loss: 0.6938 - val_accuracy: 0.5010\n","Epoch 10/10\n","625/625 [==============================] - 536s 858ms/step - loss: 0.6936 - accuracy: 0.5067 - val_loss: 0.6937 - val_accuracy: 0.4974\n"]}]},{"cell_type":"markdown","source":["# 부록"],"metadata":{"id":"rOfBgHb_LiZ6"}},{"cell_type":"markdown","source":["#### A--데이터셋을 만드는 다른 방법: tensorflow_datasets 사용하기"],"metadata":{"id":"tlhPIn46Lj64"}},{"cell_type":"code","source":["imdb_bldr = tfds.builder('imdb_reviews')\n","print(imdb_bldr.info)\n","\n","imdb_bldr.download_and_prepare()\n","\n","datasets = imdb_bldr.as_dataset(shuffle_files=False)\n","\n","datasets.keys()"],"metadata":{"id":"Go7GD7nDLjc_","colab":{"base_uri":"https://localhost:8080/","height":854,"referenced_widgets":["fbda2f2683d64031a43dec7228f8f6ed","a0a883383e674dadad24b1cfc90aea06","548c1de10abd449c8a5891b9774a32a4","3182a98be1c24a76a2dc18c2b4be9eef","1af46826615746b6b13b1ea7391a1e02","04d398775a05497d94faba74aa43618f","f858a37b8c594fc08339e0324d6b7a92","1c0b197df1f144a1a0b7ba59004de5ac","766be0820d294bf4a335e1af20596cac","f0fcc0662bfc4ac7b2b6dd92c2c24273","b86f751b7b1345f2b1e0068aca0b4882","a975f7ce05084be9b56622d925c9d4ff","9fa03292b7cf446991bec1dbe0716eaf","32687bee05ef481d83a7bfdad90f9098","64b171a331394ef2a6988fd04056bc46","040b142c9354411c9fab14abc7855923","9da14b32a8d54ddb8bf226e220a03750","cfdabeec9a39458e83a221c1700ee658","7ee85f69d0db4298b014d017653ddfb5","318af78a07af40cfbba6e3be03eccc1d","39ac980a27574b8bb0ab09f5898e608a","b0085a08925a4067a3ff248dad0c2ed8","1db9214503dd4dca80de5c18588d3a88","6801341199024adbbb2676915e8a73bf","3dc28544dc454a659a08cec5006cad6f","c604da16966d4d48a4cdf50dc86eb40d","998f77e1fea34655858354be2b3111d9","3d09c7eb7c3a458b91143eb147a404fe","61e7a9dd45cc42499148efd05e308dd6","603cabea4f604feaa3e822389921b5e6","6f7513f567eb454bb975f828985c660a","eebeb0cb51e64fa687985ac3558887ec","c154b201d25941588380ed0c3261f36b","20b59b78048f4b01bea1c492d2443314","aef0fb8226804457a7e08cec30232130","2f52d11266fe43ddb623fde7e4bf3922","0605d47338644453bb8067ded04751e5","bdd8e0ed3d9043e5b4df0d917377ae92","8cbefa1137eb45f5b731dddc522310e6","1beb61c6315444acbd7ce8a13de2cb33","203f9d685bb949388e2806469f501b5f","c4d4e185235348e5b376a122896be551","cd098abb50524b7cbef22a74dde234e2","8d8a17984eb64a719727289196acb0a4","de8a1877e5de44ff9e8db643f0ac808e","8ab27f4205bd4e19a519a1bf68d17575","98dbdaeccfb040adb0db6476da071ee6","b47e797a22b04d419b887c596aa1c30c","167622ec1719431998851d97da09e0ba","d90bad595fe749c7be11480f0054eb51","4de1a33915a04a798078fba4b115f651","22fea386d5fc4cff8a5ee8ed10f67e20","c2e5ea42b89a41528fc0ec80b7b4e25e","2dce58f292334d94b7bdd9e6d0f064d9","902320edce1e4d83b4e0db1958f4b819","f51c0d1ada3746179f2168943711cf9c","7f804b1add654f629ab844618a941011","abdabdc1291643429a45a2464e720bbe","f0a3ff8bc4ec43ce968f7c5d36f44890","e170b87f253f43e2912ff84f7a73f31b","bf69d84fcf89456ebb6466fbb423113a","032a3db1d14a4cb88772ed9cf2feaf79","a561f0b43dd247be9240277de9a23fcc","bc6eeabd85a04556b181105c59be805f","8839d93294e64462ab8ac09a40bc397e","5af8461c46974489958d2ebea9f39e1f","eea140e942304c11a21a3819a490604c","c470c22329744ab69fb4fe46e8858802","5355adec5fe042ee8080c40f44125351","6e1f2e7bc6c347c0a5654f381ed28a66","bfa97ffc45894fc2b4fcaf7827e72f06","1825c24978a24951b18f8250708c1d01","6641ad47241542a0960c97c5094500b5","a483a3c6ec2b4dac86436d7c14dd3ef7","1ac8821cffc14c73b4c3767c537a0dd0","12a51f715bb242f693538b93de5c1017","f317250d82114af181789099302c4581","ab567e27b28145e98b4ff29692e88fc8","fddb0ccaef524c17a21e5233627063b0","89e512833cd741488093548c5ffb14ab","4b89972fe765456bb9cfda9a06b88be4","6194d1ec60b644fbb6921f8a13b167e5","f17bbd95e81c40a3b16262e8a25f6c8a","12e1bbaf0b0b443aad891a9bc38b53e5","e1de61aef0444971acb32fb4547a97bb","a0922929e2554778b0760cf3194a227d","b1f2fa2003794d57a50121ce49f31876","8b4a5bdd4f0f45a2b62f69b2b83f090c","61fb7cb31f0c42298ee4c71fce4f0fdc","6d74394a6a774bfcba6d017198163c70","0764f9700f1240f2bbb9bf75bb272de2","499b845982ef4b89ac885286fe0b5fb9","4f651322c84740bc80e615f178fcdd6f","d6bf478c4d954e9e9cfa147a15b21904","d77314c7131349538d1d4a38f2caeb6e","345c3fb78e424791ab5790a1a067bea9","6d2ba7c0ce554f97905775528a26d59f","687225bbf7114fa3b309a6027c54fa01","0075774cc5174cf8bf937348ff9494e2"]},"executionInfo":{"status":"ok","timestamp":1669294031212,"user_tz":-540,"elapsed":48361,"user":{"displayName":"한현구","userId":"08987249905342132055"}},"outputId":"131021fa-9cac-41d4-e355-d78d1d43f517"},"execution_count":41,"outputs":[{"output_type":"stream","name":"stdout","text":["tfds.core.DatasetInfo(\n","    name='imdb_reviews',\n","    full_name='imdb_reviews/plain_text/1.0.0',\n","    description=\"\"\"\n","    Large Movie Review Dataset.\n","    This is a dataset for binary sentiment classification containing substantially more data than previous benchmark datasets. We provide a set of 25,000 highly polar movie reviews for training, and 25,000 for testing. There is additional unlabeled data for use as well.\n","    \"\"\",\n","    config_description=\"\"\"\n","    Plain text\n","    \"\"\",\n","    homepage='http://ai.stanford.edu/~amaas/data/sentiment/',\n","    data_path='~/tensorflow_datasets/imdb_reviews/plain_text/1.0.0',\n","    file_format=tfrecord,\n","    download_size=80.23 MiB,\n","    dataset_size=Unknown size,\n","    features=FeaturesDict({\n","        'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=2),\n","        'text': Text(shape=(), dtype=tf.string),\n","    }),\n","    supervised_keys=('text', 'label'),\n","    disable_shuffling=False,\n","    splits={\n","        'test': <SplitInfo num_examples=25000, num_shards=1>,\n","        'train': <SplitInfo num_examples=25000, num_shards=1>,\n","        'unsupervised': <SplitInfo num_examples=50000, num_shards=1>,\n","    },\n","    citation=\"\"\"@InProceedings{maas-EtAl:2011:ACL-HLT2011,\n","      author    = {Maas, Andrew L.  and  Daly, Raymond E.  and  Pham, Peter T.  and  Huang, Dan  and  Ng, Andrew Y.  and  Potts, Christopher},\n","      title     = {Learning Word Vectors for Sentiment Analysis},\n","      booktitle = {Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies},\n","      month     = {June},\n","      year      = {2011},\n","      address   = {Portland, Oregon, USA},\n","      publisher = {Association for Computational Linguistics},\n","      pages     = {142--150},\n","      url       = {http://www.aclweb.org/anthology/P11-1015}\n","    }\"\"\",\n",")\n","Downloading and preparing dataset 80.23 MiB (download: 80.23 MiB, generated: Unknown size, total: 80.23 MiB) to ~/tensorflow_datasets/imdb_reviews/plain_text/1.0.0...\n"]},{"output_type":"display_data","data":{"text/plain":["Dl Completed...: 0 url [00:00, ? url/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fbda2f2683d64031a43dec7228f8f6ed"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Dl Size...: 0 MiB [00:00, ? MiB/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a975f7ce05084be9b56622d925c9d4ff"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Generating splits...:   0%|          | 0/3 [00:00<?, ? splits/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1db9214503dd4dca80de5c18588d3a88"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Generating train examples...:   0%|          | 0/25000 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"20b59b78048f4b01bea1c492d2443314"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Shuffling ~/tensorflow_datasets/imdb_reviews/plain_text/1.0.0.incompleteRAOOAL/imdb_reviews-train.tfrecord*...…"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"de8a1877e5de44ff9e8db643f0ac808e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Generating test examples...:   0%|          | 0/25000 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f51c0d1ada3746179f2168943711cf9c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Shuffling ~/tensorflow_datasets/imdb_reviews/plain_text/1.0.0.incompleteRAOOAL/imdb_reviews-test.tfrecord*...:…"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eea140e942304c11a21a3819a490604c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Generating unsupervised examples...:   0%|          | 0/50000 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ab567e27b28145e98b4ff29692e88fc8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Shuffling ~/tensorflow_datasets/imdb_reviews/plain_text/1.0.0.incompleteRAOOAL/imdb_reviews-unsupervised.tfrec…"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"61fb7cb31f0c42298ee4c71fce4f0fdc"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Dataset imdb_reviews downloaded and prepared to ~/tensorflow_datasets/imdb_reviews/plain_text/1.0.0. Subsequent calls will reuse this data.\n"]},{"output_type":"execute_result","data":{"text/plain":["dict_keys([Split('train'), Split('test'), Split('unsupervised')])"]},"metadata":{},"execution_count":41}]},{"cell_type":"code","source":["imdb_train = datasets['train']\n","imdb_train = datasets['test']"],"metadata":{"id":"Wmkbwj2CLrh9","executionInfo":{"status":"ok","timestamp":1669294031213,"user_tz":-540,"elapsed":34,"user":{"displayName":"한현구","userId":"08987249905342132055"}}},"execution_count":42,"outputs":[]},{"cell_type":"markdown","source":["#### B--Tokenizer와 Encoder"],"metadata":{"id":"zqNVxM2OLsZj"}},{"cell_type":"code","source":["vocab_set = {'a', 'b', 'c', 'd'}\n","encoder = tfds.deprecated.text.TokenTextEncoder(vocab_set)\n","print(encoder)\n","\n","print(encoder.encode(b'a b c d, , : .'))\n","\n","print(encoder.encode(b'a b c d e f g h i z'))"],"metadata":{"id":"nPaZkzFsLzxP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1669294031214,"user_tz":-540,"elapsed":33,"user":{"displayName":"한현구","userId":"08987249905342132055"}},"outputId":"4ae52da1-39c4-4c4f-e831-6bed202699fc"},"execution_count":43,"outputs":[{"output_type":"stream","name":"stdout","text":["<TokenTextEncoder vocab_size=6>\n","[2, 3, 4, 1]\n","[2, 3, 4, 1, 5, 5, 5, 5, 5, 5]\n"]}]},{"cell_type":"markdown","source":["#### C--케라스로 텍스트 전처리하기"],"metadata":{"id":"FQ8cQE8yL2SL"}},{"cell_type":"code","source":["TOP_K = 200\n","MAX_LEN = 10\n","\n","tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=TOP_K)\n","\n","tokenizer.fit_on_texts(['this is an example', 'je suis en forme '])\n","sequences = tokenizer.texts_to_sequences(['this is an example', 'je suis en forme '])\n","print(sequences)\n","\n","tf.keras.preprocessing.sequence.pad_sequences(sequences, maxlen=MAX_LEN)"],"metadata":{"id":"X4bRjRbzL1qB","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1669294031214,"user_tz":-540,"elapsed":28,"user":{"displayName":"한현구","userId":"08987249905342132055"}},"outputId":"2bbf593c-83f6-4f65-bf4e-2916a238513b"},"execution_count":44,"outputs":[{"output_type":"stream","name":"stdout","text":["[[1, 2, 3, 4], [5, 6, 7, 8]]\n"]},{"output_type":"execute_result","data":{"text/plain":["array([[0, 0, 0, 0, 0, 0, 1, 2, 3, 4],\n","       [0, 0, 0, 0, 0, 0, 5, 6, 7, 8]], dtype=int32)"]},"metadata":{},"execution_count":44}]},{"cell_type":"code","source":["TOP_K = 20000\n","MAX_LEN = 500\n","\n","tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=TOP_K)\n","\n","tokenizer.fit_on_texts(\n","    [example['text'].numpy().decode('utf-8') \n","     for example in imdb_train])\n","\n","x_train = tokenizer.texts_to_sequences(\n","    [example['text'].numpy().decode('utf-8')\n","     for example in imdb_train])\n","\n","print(len(x_train))\n","\n","\n","x_train_padded = tf.keras.preprocessing.sequence.pad_sequences(\n","    x_train, maxlen=MAX_LEN)\n","\n","print(x_train_padded.shape)"],"metadata":{"id":"C7WBkw6YL8u6","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1669294053026,"user_tz":-540,"elapsed":21835,"user":{"displayName":"한현구","userId":"08987249905342132055"}},"outputId":"7948ccdb-3a12-41dd-8521-3c5bc8a40898"},"execution_count":45,"outputs":[{"output_type":"stream","name":"stdout","text":["25000\n","(25000, 500)\n"]}]},{"cell_type":"markdown","source":["#### D--임베딩"],"metadata":{"id":"0nnHJYeKL51T"}},{"cell_type":"code","source":["from tensorflow.keras.layers import Embedding\n","\n","\n","tf.random.set_seed(1)\n","embed = Embedding(input_dim=100, output_dim=4)\n","\n","inp_arr = np.array([1, 98, 5, 6, 67, 45])\n","tf.print(embed(inp_arr))\n","tf.print(embed(inp_arr).shape)\n","\n","tf.print(embed(np.array([1])))"],"metadata":{"id":"__aV92fJL-ZF","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1669294053027,"user_tz":-540,"elapsed":13,"user":{"displayName":"한현구","userId":"08987249905342132055"}},"outputId":"1b5e4af9-ea2e-49a1-d97a-ee7dccdcb379"},"execution_count":46,"outputs":[{"output_type":"stream","name":"stdout","text":["[[-0.0208060984 0.0142502077 0.0475785471 -0.00649005175]\n"," [-0.00420691818 -0.0375086069 -0.00477621704 0.00311584398]\n"," [0.028728161 -0.0440448038 -0.0428906195 -0.019158531]\n"," [-0.0248817336 0.0408470519 -0.00285203382 -0.0257614851]\n"," [0.0443614833 0.00331580639 0.043055404 -0.011118304]\n"," [-0.0281324144 0.00720113516 0.0192188732 -0.0186921246]]\n","TensorShape([6, 4])\n","[[-0.0208060984 0.0142502077 0.0475785471 -0.00649005175]]\n"]}]}],"metadata":{"kernelspec":{"display_name":"Python 3.8.14 ('hg')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.14"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"a89b10a71bbbd74c2679eb33295672f2024448b5b6f1a9d866f7fe38b5792374"}},"colab":{"provenance":[]},"accelerator":"GPU","gpuClass":"standard","widgets":{"application/vnd.jupyter.widget-state+json":{"fbda2f2683d64031a43dec7228f8f6ed":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a0a883383e674dadad24b1cfc90aea06","IPY_MODEL_548c1de10abd449c8a5891b9774a32a4","IPY_MODEL_3182a98be1c24a76a2dc18c2b4be9eef"],"layout":"IPY_MODEL_1af46826615746b6b13b1ea7391a1e02"}},"a0a883383e674dadad24b1cfc90aea06":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_04d398775a05497d94faba74aa43618f","placeholder":"​","style":"IPY_MODEL_f858a37b8c594fc08339e0324d6b7a92","value":"Dl Completed...: 100%"}},"548c1de10abd449c8a5891b9774a32a4":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1c0b197df1f144a1a0b7ba59004de5ac","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_766be0820d294bf4a335e1af20596cac","value":1}},"3182a98be1c24a76a2dc18c2b4be9eef":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f0fcc0662bfc4ac7b2b6dd92c2c24273","placeholder":"​","style":"IPY_MODEL_b86f751b7b1345f2b1e0068aca0b4882","value":" 1/1 [00:09&lt;00:00,  9.29s/ url]"}},"1af46826615746b6b13b1ea7391a1e02":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"04d398775a05497d94faba74aa43618f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f858a37b8c594fc08339e0324d6b7a92":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1c0b197df1f144a1a0b7ba59004de5ac":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"766be0820d294bf4a335e1af20596cac":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f0fcc0662bfc4ac7b2b6dd92c2c24273":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b86f751b7b1345f2b1e0068aca0b4882":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a975f7ce05084be9b56622d925c9d4ff":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9fa03292b7cf446991bec1dbe0716eaf","IPY_MODEL_32687bee05ef481d83a7bfdad90f9098","IPY_MODEL_64b171a331394ef2a6988fd04056bc46"],"layout":"IPY_MODEL_040b142c9354411c9fab14abc7855923"}},"9fa03292b7cf446991bec1dbe0716eaf":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9da14b32a8d54ddb8bf226e220a03750","placeholder":"​","style":"IPY_MODEL_cfdabeec9a39458e83a221c1700ee658","value":"Dl Size...: 100%"}},"32687bee05ef481d83a7bfdad90f9098":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7ee85f69d0db4298b014d017653ddfb5","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_318af78a07af40cfbba6e3be03eccc1d","value":1}},"64b171a331394ef2a6988fd04056bc46":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_39ac980a27574b8bb0ab09f5898e608a","placeholder":"​","style":"IPY_MODEL_b0085a08925a4067a3ff248dad0c2ed8","value":" 80/80 [00:09&lt;00:00, 16.42 MiB/s]"}},"040b142c9354411c9fab14abc7855923":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9da14b32a8d54ddb8bf226e220a03750":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cfdabeec9a39458e83a221c1700ee658":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7ee85f69d0db4298b014d017653ddfb5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"318af78a07af40cfbba6e3be03eccc1d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"39ac980a27574b8bb0ab09f5898e608a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b0085a08925a4067a3ff248dad0c2ed8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1db9214503dd4dca80de5c18588d3a88":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6801341199024adbbb2676915e8a73bf","IPY_MODEL_3dc28544dc454a659a08cec5006cad6f","IPY_MODEL_c604da16966d4d48a4cdf50dc86eb40d"],"layout":"IPY_MODEL_998f77e1fea34655858354be2b3111d9"}},"6801341199024adbbb2676915e8a73bf":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3d09c7eb7c3a458b91143eb147a404fe","placeholder":"​","style":"IPY_MODEL_61e7a9dd45cc42499148efd05e308dd6","value":"Generating splits...: 100%"}},"3dc28544dc454a659a08cec5006cad6f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_603cabea4f604feaa3e822389921b5e6","max":3,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6f7513f567eb454bb975f828985c660a","value":3}},"c604da16966d4d48a4cdf50dc86eb40d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_eebeb0cb51e64fa687985ac3558887ec","placeholder":"​","style":"IPY_MODEL_c154b201d25941588380ed0c3261f36b","value":" 3/3 [00:38&lt;00:00, 13.11s/ splits]"}},"998f77e1fea34655858354be2b3111d9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":null}},"3d09c7eb7c3a458b91143eb147a404fe":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"61e7a9dd45cc42499148efd05e308dd6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"603cabea4f604feaa3e822389921b5e6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6f7513f567eb454bb975f828985c660a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"eebeb0cb51e64fa687985ac3558887ec":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c154b201d25941588380ed0c3261f36b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"20b59b78048f4b01bea1c492d2443314":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_aef0fb8226804457a7e08cec30232130","IPY_MODEL_2f52d11266fe43ddb623fde7e4bf3922","IPY_MODEL_0605d47338644453bb8067ded04751e5"],"layout":"IPY_MODEL_bdd8e0ed3d9043e5b4df0d917377ae92"}},"aef0fb8226804457a7e08cec30232130":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8cbefa1137eb45f5b731dddc522310e6","placeholder":"​","style":"IPY_MODEL_1beb61c6315444acbd7ce8a13de2cb33","value":"Generating train examples...: 100%"}},"2f52d11266fe43ddb623fde7e4bf3922":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_203f9d685bb949388e2806469f501b5f","max":25000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c4d4e185235348e5b376a122896be551","value":25000}},"0605d47338644453bb8067ded04751e5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cd098abb50524b7cbef22a74dde234e2","placeholder":"​","style":"IPY_MODEL_8d8a17984eb64a719727289196acb0a4","value":" 24909/25000 [00:07&lt;00:00, 4624.07 examples/s]"}},"bdd8e0ed3d9043e5b4df0d917377ae92":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":null}},"8cbefa1137eb45f5b731dddc522310e6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1beb61c6315444acbd7ce8a13de2cb33":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"203f9d685bb949388e2806469f501b5f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c4d4e185235348e5b376a122896be551":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"cd098abb50524b7cbef22a74dde234e2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8d8a17984eb64a719727289196acb0a4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"de8a1877e5de44ff9e8db643f0ac808e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8ab27f4205bd4e19a519a1bf68d17575","IPY_MODEL_98dbdaeccfb040adb0db6476da071ee6","IPY_MODEL_b47e797a22b04d419b887c596aa1c30c"],"layout":"IPY_MODEL_167622ec1719431998851d97da09e0ba"}},"8ab27f4205bd4e19a519a1bf68d17575":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d90bad595fe749c7be11480f0054eb51","placeholder":"​","style":"IPY_MODEL_4de1a33915a04a798078fba4b115f651","value":"Shuffling ~/tensorflow_datasets/imdb_reviews/plain_text/1.0.0.incompleteRAOOAL/imdb_reviews-train.tfrecord*...:  46%"}},"98dbdaeccfb040adb0db6476da071ee6":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_22fea386d5fc4cff8a5ee8ed10f67e20","max":25000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c2e5ea42b89a41528fc0ec80b7b4e25e","value":25000}},"b47e797a22b04d419b887c596aa1c30c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2dce58f292334d94b7bdd9e6d0f064d9","placeholder":"​","style":"IPY_MODEL_902320edce1e4d83b4e0db1958f4b819","value":" 11443/25000 [00:00&lt;00:00, 114418.92 examples/s]"}},"167622ec1719431998851d97da09e0ba":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":null}},"d90bad595fe749c7be11480f0054eb51":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4de1a33915a04a798078fba4b115f651":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"22fea386d5fc4cff8a5ee8ed10f67e20":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c2e5ea42b89a41528fc0ec80b7b4e25e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2dce58f292334d94b7bdd9e6d0f064d9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"902320edce1e4d83b4e0db1958f4b819":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f51c0d1ada3746179f2168943711cf9c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7f804b1add654f629ab844618a941011","IPY_MODEL_abdabdc1291643429a45a2464e720bbe","IPY_MODEL_f0a3ff8bc4ec43ce968f7c5d36f44890"],"layout":"IPY_MODEL_e170b87f253f43e2912ff84f7a73f31b"}},"7f804b1add654f629ab844618a941011":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bf69d84fcf89456ebb6466fbb423113a","placeholder":"​","style":"IPY_MODEL_032a3db1d14a4cb88772ed9cf2feaf79","value":"Generating test examples...:  99%"}},"abdabdc1291643429a45a2464e720bbe":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_a561f0b43dd247be9240277de9a23fcc","max":25000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_bc6eeabd85a04556b181105c59be805f","value":25000}},"f0a3ff8bc4ec43ce968f7c5d36f44890":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8839d93294e64462ab8ac09a40bc397e","placeholder":"​","style":"IPY_MODEL_5af8461c46974489958d2ebea9f39e1f","value":" 24839/25000 [00:05&lt;00:00, 4614.82 examples/s]"}},"e170b87f253f43e2912ff84f7a73f31b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":null}},"bf69d84fcf89456ebb6466fbb423113a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"032a3db1d14a4cb88772ed9cf2feaf79":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a561f0b43dd247be9240277de9a23fcc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bc6eeabd85a04556b181105c59be805f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8839d93294e64462ab8ac09a40bc397e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5af8461c46974489958d2ebea9f39e1f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"eea140e942304c11a21a3819a490604c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c470c22329744ab69fb4fe46e8858802","IPY_MODEL_5355adec5fe042ee8080c40f44125351","IPY_MODEL_6e1f2e7bc6c347c0a5654f381ed28a66"],"layout":"IPY_MODEL_bfa97ffc45894fc2b4fcaf7827e72f06"}},"c470c22329744ab69fb4fe46e8858802":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1825c24978a24951b18f8250708c1d01","placeholder":"​","style":"IPY_MODEL_6641ad47241542a0960c97c5094500b5","value":"Shuffling ~/tensorflow_datasets/imdb_reviews/plain_text/1.0.0.incompleteRAOOAL/imdb_reviews-test.tfrecord*...:  47%"}},"5355adec5fe042ee8080c40f44125351":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_a483a3c6ec2b4dac86436d7c14dd3ef7","max":25000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1ac8821cffc14c73b4c3767c537a0dd0","value":25000}},"6e1f2e7bc6c347c0a5654f381ed28a66":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_12a51f715bb242f693538b93de5c1017","placeholder":"​","style":"IPY_MODEL_f317250d82114af181789099302c4581","value":" 11788/25000 [00:00&lt;00:00, 117865.50 examples/s]"}},"bfa97ffc45894fc2b4fcaf7827e72f06":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":null}},"1825c24978a24951b18f8250708c1d01":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6641ad47241542a0960c97c5094500b5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a483a3c6ec2b4dac86436d7c14dd3ef7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1ac8821cffc14c73b4c3767c537a0dd0":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"12a51f715bb242f693538b93de5c1017":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f317250d82114af181789099302c4581":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ab567e27b28145e98b4ff29692e88fc8":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_fddb0ccaef524c17a21e5233627063b0","IPY_MODEL_89e512833cd741488093548c5ffb14ab","IPY_MODEL_4b89972fe765456bb9cfda9a06b88be4"],"layout":"IPY_MODEL_6194d1ec60b644fbb6921f8a13b167e5"}},"fddb0ccaef524c17a21e5233627063b0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f17bbd95e81c40a3b16262e8a25f6c8a","placeholder":"​","style":"IPY_MODEL_12e1bbaf0b0b443aad891a9bc38b53e5","value":"Generating unsupervised examples...:  99%"}},"89e512833cd741488093548c5ffb14ab":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_e1de61aef0444971acb32fb4547a97bb","max":50000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a0922929e2554778b0760cf3194a227d","value":50000}},"4b89972fe765456bb9cfda9a06b88be4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b1f2fa2003794d57a50121ce49f31876","placeholder":"​","style":"IPY_MODEL_8b4a5bdd4f0f45a2b62f69b2b83f090c","value":" 49715/50000 [00:14&lt;00:00, 4702.57 examples/s]"}},"6194d1ec60b644fbb6921f8a13b167e5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":null}},"f17bbd95e81c40a3b16262e8a25f6c8a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"12e1bbaf0b0b443aad891a9bc38b53e5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e1de61aef0444971acb32fb4547a97bb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a0922929e2554778b0760cf3194a227d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b1f2fa2003794d57a50121ce49f31876":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8b4a5bdd4f0f45a2b62f69b2b83f090c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"61fb7cb31f0c42298ee4c71fce4f0fdc":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6d74394a6a774bfcba6d017198163c70","IPY_MODEL_0764f9700f1240f2bbb9bf75bb272de2","IPY_MODEL_499b845982ef4b89ac885286fe0b5fb9"],"layout":"IPY_MODEL_4f651322c84740bc80e615f178fcdd6f"}},"6d74394a6a774bfcba6d017198163c70":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d6bf478c4d954e9e9cfa147a15b21904","placeholder":"​","style":"IPY_MODEL_d77314c7131349538d1d4a38f2caeb6e","value":"Shuffling ~/tensorflow_datasets/imdb_reviews/plain_text/1.0.0.incompleteRAOOAL/imdb_reviews-unsupervised.tfrecord*...:  63%"}},"0764f9700f1240f2bbb9bf75bb272de2":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_345c3fb78e424791ab5790a1a067bea9","max":50000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6d2ba7c0ce554f97905775528a26d59f","value":50000}},"499b845982ef4b89ac885286fe0b5fb9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_687225bbf7114fa3b309a6027c54fa01","placeholder":"​","style":"IPY_MODEL_0075774cc5174cf8bf937348ff9494e2","value":" 31588/50000 [00:00&lt;00:00, 176839.07 examples/s]"}},"4f651322c84740bc80e615f178fcdd6f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":null}},"d6bf478c4d954e9e9cfa147a15b21904":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d77314c7131349538d1d4a38f2caeb6e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"345c3fb78e424791ab5790a1a067bea9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6d2ba7c0ce554f97905775528a26d59f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"687225bbf7114fa3b309a6027c54fa01":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0075774cc5174cf8bf937348ff9494e2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}